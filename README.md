# FlashAttention-2-Implementation-Optimization-
 An RL Training Task for LLMs
This repository provides an application of Reinforcement Learning (RL) task to train LLM based on the implementation and optimization of FlashAttention-2 a memory-efficient attention model relying on tiling and recomputation to minimize the amount of memory used by the GPU and maximize the speed. The task resembles actual AI/ML engineering work, where the model needs to apply FlashAttention2 with several of its own changes, such as activation-aware dropout, causal masking with lookahead, and multi-precision support and optimize it to A100 GPU memory patterns. The grading pipeline has a partial-credit scoring scheme that remunerates on criteria such as memory reduction, acceleration, gradient accuracy and test coverage to achieve a desired pass rate of 10-40 percent (achieving approximately 30 percent in practice). Written to offer a variety of failure modes and incremental learning indicators, the whole solution itself is less than 300 lines of clean well-documented code and produces structured evaluation data and reports in JSON, which ensures the task satisfies all the assignments criteria and also imparts useful knowledge of how to use a GPU and train a machine learning model to optimize its usage.
